{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8170db95-56ab-4077-9d8a-e12892032600",
   "metadata": {
    "id": "8170db95-56ab-4077-9d8a-e12892032600"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as DT\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas_market_calendars as mcal\n",
    "import datetime\n",
    "#from mpl_toolkits.mplot3d import axes3d\n",
    "import scipy as sp\n",
    "import scipy.interpolate\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t, norm\n",
    "from pycopula.copula import GaussianCopula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7df7eb68-28fb-4de8-881d-83d7ba8990dd",
   "metadata": {
    "id": "7df7eb68-28fb-4de8-881d-83d7ba8990dd"
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data.index = pd.to_datetime(data['Date'], format='%m/%d/%Y')\n",
    "    data['Price'] = data['Price'].str.replace(',', '').astype(float)\n",
    "    data['Log Return'] = np.log(data['Price'] / data['Price'].shift(1))\n",
    "    data = data.dropna(subset=['Log Return'])\n",
    "    return data\n",
    "\n",
    "file_path = \"../Data CSV/SMI Historical Data.csv\"\n",
    "smi = load_data(file_path)\n",
    "\n",
    "file_path = \"../Data CSV/S&P 500 Historical Data.csv\"\n",
    "sp500 = load_data(file_path)\n",
    "\n",
    "file_path = \"../Data CSV/Euro Stoxx 50 Historical Data.csv\"\n",
    "stoxx50 = load_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "edca593e-b377-4c53-9d78-e7b6d1000115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edca593e-b377-4c53-9d78-e7b6d1000115",
    "outputId": "1053c489-ec96-486f-b692-6d31cbdecf7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loss: 0.8628979857050032\n"
     ]
    }
   ],
   "source": [
    "common_dates = list(set(stoxx50.index).intersection(set(smi.index).intersection(set(sp500.index))))\n",
    "## losing data on dates, simulation also assuming common dates, losing about 14% data\n",
    "print(\"Data Loss:\", (3*len(common_dates))/(len(stoxx50)+len(smi)+len(sp500)))\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data.index = pd.to_datetime(data['Date'], format='%m/%d/%Y')\n",
    "    data = data[data.index.isin(common_dates)]\n",
    "    data['Price'] = data['Price'].str.replace(',', '').astype(float)\n",
    "    data['Log Return'] = np.log(data['Price'] / data['Price'].shift(1))\n",
    "    data.drop(columns=[\"Change %\"], errors = \"Ignore\", inplace = True)\n",
    "    data = data.dropna(subset=['Log Return'])\n",
    "    return data\n",
    "\n",
    "file_path = \"../Data CSV/SMI Historical Data.csv\"\n",
    "smi = load_data(file_path)\n",
    "\n",
    "file_path = \"../Data CSV/S&P 500 Historical Data.csv\"\n",
    "sp500 = load_data(file_path)\n",
    "\n",
    "file_path = \"../Data CSV/Euro Stoxx 50 Historical Data.csv\"\n",
    "stoxx50 = load_data(file_path)\n",
    "\n",
    "returns = pd.DataFrame({\n",
    "    'SMI': smi['Log Return'],\n",
    "    'STOXX50': stoxx50['Log Return'],\n",
    "    'SP500': sp500['Log Return']\n",
    "}).dropna()\n",
    "\n",
    "chf = pd.read_csv(\"../Data CSV/USD_CHF Historical Data.csv\")\n",
    "chf.index = pd.DatetimeIndex(chf[\"Date\"])\n",
    "eur = pd.read_csv(\"../Data CSV/USD_EUR Historical Data.csv\")\n",
    "eur.index = pd.DatetimeIndex(eur[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb1f9dc-9f3f-469a-b562-d4281da5b1d3",
   "metadata": {
    "id": "7cb1f9dc-9f3f-469a-b562-d4281da5b1d3",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Simulation using Student T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06d6b2b8-ca52-455c-85c4-b648c88d4d18",
   "metadata": {
    "id": "06d6b2b8-ca52-455c-85c4-b648c88d4d18"
   },
   "outputs": [],
   "source": [
    "params_smi = t.fit(returns['SMI'])\n",
    "params_stoxx50 = t.fit(returns['STOXX50'])\n",
    "params_sp500 = t.fit(returns['SP500'])\n",
    "\n",
    "corr_matrix = returns.corr()\n",
    "chol_matrix = np.linalg.cholesky(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0946692-c26a-4b0c-84be-bac24f824098",
   "metadata": {
    "id": "f0946692-c26a-4b0c-84be-bac24f824098"
   },
   "outputs": [],
   "source": [
    "n_simulations = 1\n",
    "n_timesteps = 30\n",
    "\n",
    "z = np.random.normal(size=(n_timesteps, n_simulations, 3))\n",
    "correlated_z = np.matmul(z, chol_matrix.T)\n",
    "u = norm.cdf(correlated_z)\n",
    "\n",
    "sim_smi = t.ppf(u[:, :, 0], *params_smi)\n",
    "sim_stoxx50 = t.ppf(u[:, :, 1], *params_stoxx50)\n",
    "sim_sp500 = t.ppf(u[:, :, 2], *params_sp500)\n",
    "\n",
    "initial_prices = {\n",
    "    'SMI': smi['Price'].iloc[-1],\n",
    "    'STOXX50': stoxx50['Price'].iloc[-1],\n",
    "    'SP500': sp500['Price'].iloc[-1]\n",
    "}\n",
    "\n",
    "price_paths_smi = initial_prices['SMI'] * np.exp(np.cumsum(sim_smi, axis=0))\n",
    "price_paths_stoxx50 = initial_prices['STOXX50'] * np.exp(np.cumsum(sim_stoxx50, axis=0))\n",
    "price_paths_sp500 = initial_prices['SP500'] * np.exp(np.cumsum(sim_sp500, axis=0))\n",
    "\n",
    "price_paths = {\n",
    "    'SMI': price_paths_smi,\n",
    "    'STOXX50': price_paths_stoxx50,\n",
    "    'SP500': price_paths_sp500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "qS5XxLeEB5-3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "qS5XxLeEB5-3",
    "outputId": "8071920b-97ad-494c-a016-0d23cbed7d94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMI</th>\n",
       "      <th>STOXX50</th>\n",
       "      <th>SP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SMI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792476</td>\n",
       "      <td>0.500997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOXX50</th>\n",
       "      <td>0.792476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP500</th>\n",
       "      <td>0.500997</td>\n",
       "      <td>0.592506</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SMI   STOXX50     SP500\n",
       "SMI      1.000000  0.792476  0.500997\n",
       "STOXX50  0.792476  1.000000  0.592506\n",
       "SP500    0.500997  0.592506  1.000000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa5034-b7bb-4183-b2c3-3d52f81f2322",
   "metadata": {
    "id": "4baa5034-b7bb-4183-b2c3-3d52f81f2322"
   },
   "source": [
    "## Simulation using GBM with the CIR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GIXEDxfjLWf0",
   "metadata": {
    "id": "GIXEDxfjLWf0"
   },
   "source": [
    "Using an MLE to estimate paramters for the CIR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bXDM-b_GKAJE",
   "metadata": {
    "id": "bXDM-b_GKAJE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.92 1.88 1.82 ... 4.42 4.31 4.3 ]\n",
      "Fitted Parameters:\n",
      "kappa: 0.12479397159019213\n",
      "theta: 6.461329307892663\n",
      "sigma_r: 0.6839524029950487\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load data\n",
    "interest_rates = pd.read_excel(\"../Data CSV/US Interest Rates.xlsx\")\n",
    "interest_rates.columns = interest_rates.columns.str.strip()\n",
    "interest_rates = interest_rates.dropna(subset=[\"United States Treasury 10-YR Rates\"])\n",
    "interest_rates[\"United States Treasury 10-YR Rates\"] = pd.to_numeric(\n",
    "    interest_rates[\"United States Treasury 10-YR Rates\"], errors=\"coerce\"\n",
    ")\n",
    "r = interest_rates[\"United States Treasury 10-YR Rates\"].dropna().values\n",
    "\n",
    "print(r)\n",
    "\n",
    "dt = 1 / 252  # Time step\n",
    "\n",
    "# log-likelihood function assumes:\n",
    "# dr ~ N (mean_increment, variance_increment)\n",
    "\n",
    "# Define negative log-likelihood function\n",
    "def negative_log_likelihood(params, r, dt):\n",
    "    kappa, theta, sigma_r = params\n",
    "    if kappa <= 0 or sigma_r <= 0:\n",
    "        return np.inf\n",
    "    log_likelihood = 0\n",
    "    for t in range(len(r) - 1):\n",
    "        dr = r[t + 1] - r[t]\n",
    "        mean_increment = kappa * (theta - r[t]) * dt\n",
    "        variance_increment = sigma_r**2 * r[t] * dt\n",
    "        if variance_increment <= 0:\n",
    "            return np.inf\n",
    "        likelihood_t = -0.5 * np.log(2 * np.pi * variance_increment) - 0.5 * (\n",
    "            (dr - mean_increment) ** 2 / variance_increment\n",
    "        )\n",
    "        log_likelihood += likelihood_t\n",
    "    return -log_likelihood\n",
    "\n",
    "# Initial guesses and bounds\n",
    "initial_vals = [0.1, np.mean(r), np.std(r)]\n",
    "bounds = ((1e-5, None), (None, None), (1e-5, None))\n",
    "\n",
    "# Optimization\n",
    "result = minimize(\n",
    "    negative_log_likelihood, initial_vals, args=(r, dt), bounds=bounds, method=\"L-BFGS-B\"\n",
    ")\n",
    "\n",
    "kappa, theta, sigma_r = result.x\n",
    "print(\"Fitted Parameters:\")\n",
    "print(\"kappa:\", kappa)\n",
    "print(\"theta:\", theta)\n",
    "print(\"sigma_r:\", sigma_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28939021-bb4c-4ce5-8bab-9933b1f67f6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "28939021-bb4c-4ce5-8bab-9933b1f67f6a",
    "outputId": "afacebd8-8b05-4900-e180-5033741344c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SMI': np.float64(0.15212714616824494), 'STOXX50': np.float64(0.1947607348796791), 'SP500': np.float64(0.17623741746668914)}\n",
      "{'SMI': array([[8270.46, 8270.46, 8270.46, ..., 8270.46, 8270.46, 8270.46],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       ...,\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ]]), 'STOXX50': array([[3074.43, 3074.43, 3074.43, ..., 3074.43, 3074.43, 3074.43],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       ...,\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ],\n",
      "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,    0.  ]]), 'SP500': array([[1831.4, 1831.4, 1831.4, ..., 1831.4, 1831.4, 1831.4],\n",
      "       [   0. ,    0. ,    0. , ...,    0. ,    0. ,    0. ],\n",
      "       [   0. ,    0. ,    0. , ...,    0. ,    0. ,    0. ],\n",
      "       ...,\n",
      "       [   0. ,    0. ,    0. , ...,    0. ,    0. ,    0. ],\n",
      "       [   0. ,    0. ,    0. , ...,    0. ,    0. ,    0. ],\n",
      "       [   0. ,    0. ,    0. , ...,    0. ,    0. ,    0. ]])}\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "start_date = '2024-08-01'\n",
    "final_date= '2024-09-16'\n",
    "n_simulations = 10000\n",
    "n_timesteps = len(pd.bdate_range(start=start_date,end=final_date))\n",
    "\n",
    "mu = {}\n",
    "sigma = {}\n",
    "for index in ['SMI', 'STOXX50', 'SP500']:\n",
    "    mean_return = returns[index].mean()\n",
    "    variance = returns[index].var()\n",
    "    mu[index] = mean_return\n",
    "    sigma[index] = np.sqrt(variance)*np.sqrt(252)\n",
    "print(sigma)\n",
    "\n",
    "corr_matrix = returns.corr()\n",
    "chol_matrix = np.linalg.cholesky(corr_matrix)\n",
    "\n",
    "Z = np.random.normal(size=(n_timesteps, n_simulations, 3))\n",
    "Z_flat = Z.reshape(-1, 3)\n",
    "Z_correlated_flat = Z_flat @ chol_matrix.T\n",
    "Z_correlated = Z_correlated_flat.reshape(n_timesteps, n_simulations, 3)\n",
    "\n",
    "initial_prices = {\n",
    "    'SMI': smi['Price'].iloc[-1],\n",
    "    'STOXX50': stoxx50['Price'].iloc[-1],\n",
    "    'SP500': sp500['Price'].iloc[-1]\n",
    "}\n",
    "\n",
    "price_paths = {index: np.zeros((n_timesteps + 1, n_simulations)) for index in ['SMI', 'STOXX50', 'SP500']}\n",
    "for index in ['SMI', 'STOXX50', 'SP500']:\n",
    "    price_paths[index][0] = initial_prices[index]\n",
    "print(price_paths)\n",
    "\n",
    "initial_rate = r[-1]\n",
    "r_paths = np.zeros((n_timesteps + 1, n_simulations))\n",
    "r_paths[0, :] = initial_rate\n",
    "\n",
    "\n",
    "for i in range(1, n_timesteps + 1):\n",
    "    Z_r = np.random.normal(size=n_simulations)\n",
    "    r_t_prev = r_paths[i - 1]\n",
    "    dr = kappa * (theta - r_t_prev) * dt + sigma_r * np.sqrt(r_t_prev * dt) * Z_r\n",
    "    r_paths[i] = np.maximum(r_t_prev + dr, 0)\n",
    "\n",
    "    for idx, index in enumerate(['SMI', 'STOXX50', 'SP500']):\n",
    "        drift_term = (np.log(1+r_paths[i]*0.01) - 0.5 * sigma[index] ** 2) * dt\n",
    "        diffusion_term = sigma[index] * np.sqrt(dt) * Z_correlated[i - 1, :, idx]\n",
    "        price_paths[index][i] = price_paths[index][i - 1] * np.exp(drift_term + diffusion_term)\n",
    "\n",
    "for index in ['SMI', 'STOXX50', 'SP500']:\n",
    "    price_paths[index] = price_paths[index].transpose()\n",
    "for i in r_paths:\n",
    "    print(len(i))\n",
    "print(len(r_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f618a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m T \u001b[38;5;241m=\u001b[39m (pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mfinal_date\u001b[49m) \u001b[38;5;241m-\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date))\u001b[38;5;241m.\u001b[39mdays\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m356\u001b[39m\n\u001b[1;32m      3\u001b[0m sp500_init_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3977\u001b[39m\n\u001b[1;32m      4\u001b[0m sp500_barrier \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2585\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_date' is not defined"
     ]
    }
   ],
   "source": [
    "T = n_timesteps/356\n",
    "\n",
    "sp500_init_level = 3977\n",
    "sp500_barrier = 2585\n",
    "\n",
    "stoxx_init_level = 4164\n",
    "stoxx_init_level = stoxx_init_level*eur[\"Price\"][start_date]\n",
    "stoxx_barrier = 2707\n",
    "stoxx_barrier = stoxx_barrier*eur[\"Price\"][start_date]\n",
    "\n",
    "\n",
    "smi_init_level = 10786\n",
    "smi_init_level = smi_init_level*chf[\"Price\"][start_date]\n",
    "smi_barrier = 7011\n",
    "smi_barrier = smi_barrier*chf[\"Price\"][start_date]\n",
    "#smi_barrier = smi_init_level*0.65\n",
    "\n",
    "l = []\n",
    "for i in range(len(price_paths['SMI'])):\n",
    "    discount_factor = math.e**(-np.average(r_paths[i])*T)\n",
    "    sim = pd.DataFrame({\n",
    "        'Date': pd.bdate_range(start=start_date,end=final_date), \n",
    "        'SMI': price_paths['SMI'][i][:n_timesteps], \n",
    "        'SP500': price_paths['SP500'][i][:n_timesteps], \n",
    "        'STOXX50': price_paths['STOXX50'][i][:n_timesteps]})\n",
    "    \n",
    "    barrier = False\n",
    "    if len(sim[(sim['SMI'] < smi_barrier)]) > 0 or len(sim[(sim['SP500'] < sp500_barrier)]) > 0 or len(sim[(sim['STOXX50'] < stoxx_barrier)])>0 :\n",
    "        barrier = True\n",
    "    if not barrier:\n",
    "        l.append(1000*discount_factor)\n",
    "    else:\n",
    "        l.append(discount_factor*1000*min(1, sim['SMI'].iloc[-1]/smi_init_level, sim['SP500'].iloc[-1]/sp500_init_level, sim['STOXX50'].iloc[-1]/stoxx_init_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_simulations):\n",
    "    plt.plot(range(n_timesteps + 1), r_paths[:, i], lw=0.8)\n",
    "plt.xlabel(\"Time (Days)\")\n",
    "plt.ylabel(\"Interest Rate (r)\")\n",
    "plt.title(\"Simulated CIR Paths for Interest Rate\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_simulations):\n",
    "    plt.plot(range(n_timesteps + 1), price_paths['SMI'][i, :], lw=0.8)\n",
    "plt.xlabel(\"Time (Days)\")\n",
    "plt.ylabel(\"SMI Price\")\n",
    "plt.title(\"Simulated GBM Paths with Stochastic Interest Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1c116-5857-4e56-b9e1-bcc908d8c7a5",
   "metadata": {
    "id": "adc1c116-5857-4e56-b9e1-bcc908d8c7a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smi markov:\n",
      "            GDP_YoY%  CPI_YoY%  Combined_Regime\n",
      "Period                                         \n",
      "2000-03-31    0.0426      1.96                4\n",
      "2000-04-30    0.0426      1.71                4\n",
      "2000-05-31    0.0426      1.76                4\n",
      "2000-06-30    0.0467      2.14                4\n",
      "2000-07-31    0.0467      2.09                4\n",
      "...              ...       ...              ...\n",
      "2024-04-30    0.0046      2.37                3\n",
      "2024-05-31    0.0046      2.57                3\n",
      "2024-06-30    0.0060      2.52                3\n",
      "2024-07-31    0.0060      2.58                3\n",
      "2024-08-31    0.0060      2.17                3\n",
      "\n",
      "[294 rows x 3 columns]\n",
      "sp500:\n",
      "            GDP_YoY%  CPI_YoY%  Combined_Regime\n",
      "Period                                         \n",
      "2000-03-31    0.0432      1.48                2\n",
      "2000-04-30    0.0432      1.40                2\n",
      "2000-05-31    0.0432      1.58                2\n",
      "2000-06-30    0.0410      1.84                2\n",
      "2000-07-31    0.0410      1.89                2\n",
      "...              ...       ...              ...\n",
      "2024-04-30    0.0074      1.37                1\n",
      "2024-05-31    0.0074      1.39                1\n",
      "2024-06-30    0.0169      1.33                1\n",
      "2024-07-31    0.0169      1.29                1\n",
      "2024-08-31    0.0169      1.06                1\n",
      "\n",
      "[294 rows x 3 columns]\n",
      "stoxx50:\n",
      "            GDP_YoY%  CPI_YoY%  Combined_Regime\n",
      "Period                                         \n",
      "2000-03-31    0.0422      3.76                4\n",
      "2000-04-30    0.0422      3.07                4\n",
      "2000-05-31    0.0422      3.19                4\n",
      "2000-06-30    0.0524      3.73                4\n",
      "2000-07-31    0.0524      3.66                4\n",
      "...              ...       ...              ...\n",
      "2024-04-30    0.0290      3.36                3\n",
      "2024-05-31    0.0290      3.27                3\n",
      "2024-06-30    0.0304      2.97                3\n",
      "2024-07-31    0.0304      2.89                3\n",
      "2024-08-31    0.0304      2.53                3\n",
      "\n",
      "[294 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path, date_column='Period'):\n",
    "    \"\"\"\n",
    "    Load CSV data, parse the date column, and return a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the CSV file.\n",
    "    - date_column (str): Column name containing date information.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Loaded and processed DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        if date_column in data.columns:\n",
    "            data[date_column] = pd.to_datetime(data[date_column])\n",
    "            data.set_index(date_column, inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: '{date_column}' column not found in {file_path}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found - {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An error occurred while loading {file_path} - {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load datasets\n",
    "smi_file_path = \"../Data CSV/EurozoneMarkov.csv\"\n",
    "smi_markov = load_data(smi_file_path)\n",
    "\n",
    "sp500_file_path = \"../Data CSV/SwitzerlandMarkov.csv\"\n",
    "sp500_markov = load_data(sp500_file_path)\n",
    "\n",
    "stoxx50_file_path = \"../Data CSV/USAMarkov.csv\"\n",
    "stoxx50_markov = load_data(stoxx50_file_path)\n",
    "\n",
    "# Display one of the datasets\n",
    "print(\"smi markov:\")\n",
    "print(smi_markov)\n",
    "print(\"sp500:\")\n",
    "print(sp500_markov)\n",
    "print(\"stoxx50:\")\n",
    "print(stoxx50_markov)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex the 'Combined_Regime' to daily frequency, forward-filling\n",
    "smi_regime_daily = smi_markov['Combined_Regime'].reindex(returns.index, method='ffill')\n",
    "sp500_regime_daily = sp500_markov['Combined_Regime'].reindex(returns.index, method='ffill')\n",
    "stoxx50_regime_daily = stoxx50_markov['Combined_Regime'].reindex(returns.index, method='ffill')\n",
    "\n",
    "# Add the regimes to the returns DataFrame\n",
    "returns['SMI_Regime'] = smi_regime_daily\n",
    "returns['SP500_Regime'] = sp500_regime_daily\n",
    "returns['STOXX50_Regime'] = stoxx50_regime_daily\n",
    "\n",
    "# Drop rows with missing regime data\n",
    "returns.dropna(subset=['SMI_Regime', 'SP500_Regime', 'STOXX50_Regime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1bcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMI</th>\n",
       "      <th>STOXX50</th>\n",
       "      <th>SP500</th>\n",
       "      <th>SMI_Regime</th>\n",
       "      <th>SP500_Regime</th>\n",
       "      <th>STOXX50_Regime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-28</th>\n",
       "      <td>0.011291</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25</th>\n",
       "      <td>-0.004420</td>\n",
       "      <td>-0.005395</td>\n",
       "      <td>-0.002648</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24</th>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>-0.002133</td>\n",
       "      <td>-0.002617</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-22</th>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-09</th>\n",
       "      <td>-0.008309</td>\n",
       "      <td>-0.004485</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>-0.004009</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>-0.005686</td>\n",
       "      <td>-0.013527</td>\n",
       "      <td>-0.006058</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2655 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SMI   STOXX50     SP500  SMI_Regime  SP500_Regime  \\\n",
       "Date                                                                 \n",
       "2024-10-28  0.011291  0.003994 -0.001613           3             1   \n",
       "2024-10-25 -0.004420 -0.005395 -0.002648           3             1   \n",
       "2024-10-24 -0.000900 -0.001547  0.000300           3             1   \n",
       "2024-10-23 -0.002133 -0.002617 -0.002143           3             1   \n",
       "2024-10-22  0.001335  0.003399  0.009234           3             1   \n",
       "...              ...       ...       ...         ...           ...   \n",
       "2014-01-09 -0.008309 -0.004485 -0.002337           1             3   \n",
       "2014-01-08  0.006838  0.006580 -0.000326           1             3   \n",
       "2014-01-07 -0.004009  0.000096  0.000218           1             3   \n",
       "2014-01-06 -0.005686 -0.013527 -0.006058           1             3   \n",
       "2014-01-03 -0.000214  0.001716  0.002515           1             3   \n",
       "\n",
       "            STOXX50_Regime  \n",
       "Date                        \n",
       "2024-10-28               3  \n",
       "2024-10-25               3  \n",
       "2024-10-24               3  \n",
       "2024-10-23               3  \n",
       "2024-10-22               3  \n",
       "...                    ...  \n",
       "2014-01-09               1  \n",
       "2014-01-08               1  \n",
       "2014-01-07               1  \n",
       "2014-01-06               1  \n",
       "2014-01-03               1  \n",
       "\n",
       "[2655 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801645b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = ['SMI', 'SP500', 'STOXX50']\n",
    "regime_params = {}\n",
    "\n",
    "for asset in assets:\n",
    "    regime_params[asset] = {}\n",
    "    for regime in returns[asset + '_Regime'].unique():\n",
    "        mask = returns[asset + '_Regime'] == regime\n",
    "        returns_in_regime = returns.loc[mask, asset]\n",
    "        mean_return = returns_in_regime.mean()\n",
    "        volatility = returns_in_regime.std()\n",
    "        regime_params[asset][regime] = {\n",
    "            'mean_return': mean_return,\n",
    "            'volatility': volatility\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152337b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SMI': {np.int64(3): {'mean_return': np.float64(-0.00028091200610514094),\n",
       "   'volatility': np.float64(0.007551913402508472)},\n",
       "  np.int64(4): {'mean_return': np.float64(0.00020209597096885904),\n",
       "   'volatility': np.float64(0.009131288876540663)},\n",
       "  np.int64(2): {'mean_return': np.float64(-0.0006339429417086586),\n",
       "   'volatility': np.float64(0.009676166710764164)},\n",
       "  np.int64(1): {'mean_return': np.float64(2.0785260995903307e-05),\n",
       "   'volatility': np.float64(0.011560382307194618)}},\n",
       " 'SP500': {np.int64(1): {'mean_return': np.float64(-0.0005962061918581951),\n",
       "   'volatility': np.float64(0.008180303566778162)},\n",
       "  np.int64(2): {'mean_return': np.float64(-0.00046204215025107186),\n",
       "   'volatility': np.float64(0.00816799795668507)},\n",
       "  np.int64(4): {'mean_return': np.float64(-0.0005576473498891349),\n",
       "   'volatility': np.float64(0.013724776184802974)},\n",
       "  np.int64(3): {'mean_return': np.float64(-0.00027629539108563693),\n",
       "   'volatility': np.float64(0.01241592578251177)}},\n",
       " 'STOXX50': {np.int64(3): {'mean_return': np.float64(-0.00044988899474954355),\n",
       "   'volatility': np.float64(0.010039677154713484)},\n",
       "  np.int64(4): {'mean_return': np.float64(0.00017836486218941768),\n",
       "   'volatility': np.float64(0.013516144821171444)},\n",
       "  np.int64(2): {'mean_return': np.float64(-0.0010154685409313172),\n",
       "   'volatility': np.float64(0.012269938280881158)},\n",
       "  np.int64(1): {'mean_return': np.float64(-1.6812554373025327e-05),\n",
       "   'volatility': np.float64(0.01280565801746341)}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regime_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0005576473498891349\n",
      "0.009131288876540663\n"
     ]
    }
   ],
   "source": [
    "# Example of accessing the parameters\n",
    "print(regime_params['SP500'][4]['mean_return'])\n",
    "print(regime_params['SMI'][4]['volatility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrices = {}\n",
    "\n",
    "for asset in assets:\n",
    "    regimes = sorted(returns[asset + '_Regime'].unique())\n",
    "    n_regimes = len(regimes)\n",
    "    counts = np.zeros((n_regimes, n_regimes))\n",
    "    total_counts = np.zeros(n_regimes)\n",
    "\n",
    "    asset_regimes = returns[asset + '_Regime'].values.astype(int)\n",
    "    for t in range(len(asset_regimes) - 1):\n",
    "        current_regime = asset_regimes[t] - 1  # Adjusting for zero-based indexing\n",
    "        next_regime = asset_regimes[t + 1] - 1\n",
    "        counts[current_regime, next_regime] += 1\n",
    "        total_counts[current_regime] += 1\n",
    "\n",
    "    transition_matrix = counts / total_counts[:, None]\n",
    "    transition_matrices[asset] = np.nan_to_num(transition_matrix)\n",
    "\n",
    "# Example of accessing the transition matrix\n",
    "# transition_matrices['SMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2024-08-01'\n",
    "n_simulations = 100\n",
    "n_timesteps = len(pd.bdate_range(start='2024-08-01',end='2024-12-16')) # Number of trading days in a year\n",
    "\n",
    "regime_paths = {}\n",
    "\n",
    "for asset in assets:\n",
    "    regimes = sorted(returns[asset + '_Regime'].unique())\n",
    "    n_regimes = len(regimes)\n",
    "    transition_matrix = transition_matrices[asset]\n",
    "\n",
    "    # Initialize regime paths\n",
    "    regime_paths[asset] = np.zeros((n_simulations, n_timesteps), dtype=int)\n",
    "    initial_regime = int(returns[asset + '_Regime'].iloc[-1]) - 1  # Zero-based index\n",
    "    regime_paths[asset][:, 0] = initial_regime\n",
    "\n",
    "    for t in range(1, n_timesteps):\n",
    "        current_regimes = regime_paths[asset][:, t - 1]\n",
    "        probs = transition_matrix[current_regimes]\n",
    "        random_values = np.random.rand(n_simulations)\n",
    "        cumulative_probs = probs.cumsum(axis=1)\n",
    "        next_regimes = (random_values[:, None] < cumulative_probs).argmax(axis=1)\n",
    "        regime_paths[asset][:, t] = next_regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = {}\n",
    "volatility = {}\n",
    "\n",
    "for asset in assets:\n",
    "    drift[asset] = np.zeros((n_simulations, n_timesteps))\n",
    "    volatility[asset] = np.zeros((n_simulations, n_timesteps))\n",
    "    for regime in regime_params[asset]:\n",
    "        mask = regime_paths[asset] == (regime - 1)\n",
    "        drift[asset][mask] = regime_params[asset][regime]['mean_return']\n",
    "        volatility[asset][mask] = regime_params[asset][regime]['volatility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e09d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'volatility_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 53\u001b[0m\n\u001b[1;32m     45\u001b[0m Z_correlated \u001b[38;5;241m=\u001b[39m Z \u001b[38;5;241m@\u001b[39m chol_matrix\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, asset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTOXX50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSP500\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Retrieve drift and volatility based on regimes\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m#drift_t = drift[asset][:, t - 1]\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m#volatility_t = volatility[asset][:, t - 1]\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Calculate drift term using the stochastic interest rate\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     drift_term \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mr_t) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mvolatility_t\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m dt\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Calculate diffusion term\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     diffusion_term \u001b[38;5;241m=\u001b[39m volatility_t \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(dt) \u001b[38;5;241m*\u001b[39m Z_correlated[:, idx]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'volatility_t' is not defined"
     ]
    }
   ],
   "source": [
    "# Historical correlation matrix\n",
    "corr_matrix = returns[['SMI', 'SP500', 'STOXX50']].corr()\n",
    "chol_matrix = np.linalg.cholesky(corr_matrix)\n",
    "\n",
    "# Generate correlated random variables\n",
    "Z = np.random.normal(size=(n_simulations, n_timesteps, 3))\n",
    "Z_flat = Z.reshape(-1, 3)\n",
    "Z_correlated_flat = Z_flat @ chol_matrix.T\n",
    "Z_correlated = Z_correlated_flat.reshape(n_simulations, n_timesteps, 3)\n",
    "\n",
    "dt = 1 / 252  # Daily time step\n",
    "\n",
    "# Initialize interest rate paths\n",
    "initial_rate = r[-1]\n",
    "r_paths = np.zeros((n_simulations, n_timesteps + 1))\n",
    "r_paths[:, 0] = initial_rate\n",
    "\n",
    "# Simulate interest rate paths\n",
    "for t in range(1, n_timesteps + 1):\n",
    "    Z_r = np.random.normal(size=n_simulations)\n",
    "    r_t_prev = r_paths[:, t - 1]\n",
    "    dr = kappa * (theta - r_t_prev) * dt + sigma_r * np.sqrt(r_t_prev * dt) * Z_r\n",
    "    r_paths[:, t] = np.maximum(r_t_prev + dr, 0)\n",
    "\n",
    "# Initialize price paths with correct dimensions\n",
    "price_paths = {index: np.zeros((n_simulations, n_timesteps + 1)) for index in ['SMI', 'STOXX50', 'SP500']}\n",
    "for index in ['SMI', 'STOXX50', 'SP500']:\n",
    "    price_paths[index][:, 0] = initial_prices[index]\n",
    "\n",
    "# Initialize interest rate paths\n",
    "r_paths = np.zeros((n_simulations, n_timesteps + 1))\n",
    "r_paths[:, 0] = initial_rate\n",
    "\n",
    "# Simulation loop\n",
    "for t in range(1, n_timesteps + 1):\n",
    "    # Simulate interest rates\n",
    "    Z_r = np.random.normal(size=n_simulations)\n",
    "    r_t_prev = r_paths[:, t - 1]\n",
    "    dr = kappa * (theta - r_t_prev) * dt + sigma_r * np.sqrt(np.maximum(r_t_prev, 0) * dt) * Z_r\n",
    "    r_paths[:, t] = np.maximum(r_t_prev + dr, 0)\n",
    "    r_t = r_paths[:, t]\n",
    "    \n",
    "    # Generate correlated random variables\n",
    "    Z = np.random.normal(size=(n_simulations, 3))\n",
    "    Z_correlated = Z @ chol_matrix.T\n",
    "\n",
    "    for idx, asset in enumerate(['SMI', 'STOXX50', 'SP500']):\n",
    "        # Retrieve drift and volatility based on regimes\n",
    "        #drift_t = drift[asset][:, t - 1]\n",
    "        #volatility_t = volatility[asset][:, t - 1]\n",
    "\n",
    "        # Calculate drift term using the stochastic interest rate\n",
    "        drift_term = (np.log(1+r_t) - 0.5 * volatility_t ** 2) * dt\n",
    "\n",
    "        # Calculate diffusion term\n",
    "        diffusion_term = volatility_t * np.sqrt(dt) * Z_correlated[:, idx]\n",
    "\n",
    "        # Update asset prices\n",
    "        price_paths[asset][:, t] = price_paths[asset][:, t - 1] * np.exp(drift_term + diffusion_term)\n",
    "\n",
    "# Plotting\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(min(n_simulations, 50)):  # Plotting fewer paths for clarity\n",
    "    plt.plot(range(n_timesteps + 1), r_paths[i, :], lw=0.8)\n",
    "plt.xlabel(\"Time (Days)\")\n",
    "plt.ylabel(\"Interest Rate (r)\")\n",
    "plt.title(\"Simulated CIR Paths for Interest Rate\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(min(n_simulations, 1000)):\n",
    "    plt.plot(range(n_timesteps + 1), price_paths['SMI'][i, :], lw=0.8)\n",
    "plt.xlabel(\"Time (Days)\")\n",
    "plt.ylabel(\"SMI Price\")\n",
    "plt.title(\"Simulated GBM Paths with Stochastic Interest Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b629d1-9594-480a-92f7-a45ba1ff8b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
